{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fce93c-0c95-4975-8d28-874375d81a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torch.nn.functional import softmax\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import numpy as np\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from transformers import TrainerCallback, AdamW, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "423b1928-bbe8-4ea8-b633-24789cf3441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Old caching folder /home/bashyalb/.cache/huggingface/datasets/json/default-f99c3fcb22cc41b9/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96 for dataset json exists but no data were found. Removing it. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b21544686fa48e081150b3496ce9b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ner_tags', 'id', 'split_tokens'],\n",
      "        num_rows: 401\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['ner_tags', 'id', 'split_tokens'],\n",
      "        num_rows: 71\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files ='../Data/biloc_tagged_clauses.json'\n",
    "datasets = load_dataset('json', data_files=data_files, field='data')\n",
    "test_size=0.15\n",
    "random_seed=42\n",
    "\n",
    "datasets = datasets['train'].train_test_split(test_size=test_size, seed=random_seed)\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d12e0e8-bef4-44b9-ab4a-8eba15ac73d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'EXHIBIT',\n",
       " '10.4',\n",
       " 'SPONSORSHIP',\n",
       " 'AGREEMENT',\n",
       " '---------------------',\n",
       " 'This',\n",
       " 'Sponsorship',\n",
       " 'Agreement',\n",
       " 'is',\n",
       " 'made',\n",
       " 'between',\n",
       " 'National',\n",
       " 'Processing',\n",
       " 'Company']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0][\"split_tokens\"][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d57b457-588a-42dc-a66d-11b7a7f87bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 5, 6, 7]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0][\"ner_tags\"][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453aa3a5-1e65-448e-8b69-6e985ec90007",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/feature_class_labels.json', 'r') as f:\n",
    "    label_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f131bd8-a543-4260-95a6-b2c2b33980f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a7bc412-9f60-4f0e-9403-3983cab0e3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bb17a4369b4deaa8fe4b37e4f7780c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255f8142a20e4b91ac4da7c3d9a33c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f0b466d37d4d17b49cb9b558e6117c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18aa5655-cc0c-4322-b430-918f315c77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"split_tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8489943e-3c0c-4e0b-8459-f623be572e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7281845753974ed3b72c219f4b2eac9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fefe5fd04f49738f13fb21c61a6fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset=datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae630402-e39b-46c0-b61f-6ae92ffac22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e833d723-1ae5-4e8b-b24b-b3e5efb58bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db77da73748e47159edbea1ed37f6ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0e0f936-2ff3-45ab-a6bc-8ace430151c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[id2label[p] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[id2label[l] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    # Assuming you have a seqeval wrapper or configuration that accepts scheme specification\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ec6772f-2d3a-4acc-a70b-f606c541981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/feature_class_labels.json', 'r') as f:\n",
    "    label_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2b3dcf9-7b43-46be-bcff-3a573c56ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {id: label for id, label in enumerate(label_list)}\n",
    "\n",
    "label2id = {label: id for id, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1737f3-ff3c-410f-bce1-2aebea8be51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=165, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28456a29-13c2-42a9-856a-e24dc62c4345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 11:26, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.994327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.132200</td>\n",
       "      <td>0.905949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.912800</td>\n",
       "      <td>0.847343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.868500</td>\n",
       "      <td>0.782075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.869968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.746300</td>\n",
       "      <td>0.725387</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.869292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.680321</td>\n",
       "      <td>0.309045</td>\n",
       "      <td>0.147659</td>\n",
       "      <td>0.199838</td>\n",
       "      <td>0.874940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.620243</td>\n",
       "      <td>0.336887</td>\n",
       "      <td>0.189676</td>\n",
       "      <td>0.242704</td>\n",
       "      <td>0.877088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.587726</td>\n",
       "      <td>0.351181</td>\n",
       "      <td>0.535414</td>\n",
       "      <td>0.424156</td>\n",
       "      <td>0.870843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.518200</td>\n",
       "      <td>0.529854</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.277311</td>\n",
       "      <td>0.304950</td>\n",
       "      <td>0.883572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.487421</td>\n",
       "      <td>0.409541</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.468107</td>\n",
       "      <td>0.890334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.487924</td>\n",
       "      <td>0.413179</td>\n",
       "      <td>0.557023</td>\n",
       "      <td>0.474438</td>\n",
       "      <td>0.894153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>0.452033</td>\n",
       "      <td>0.441361</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.505641</td>\n",
       "      <td>0.897454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.449126</td>\n",
       "      <td>0.439127</td>\n",
       "      <td>0.627851</td>\n",
       "      <td>0.516798</td>\n",
       "      <td>0.899364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.258900</td>\n",
       "      <td>0.458098</td>\n",
       "      <td>0.428821</td>\n",
       "      <td>0.589436</td>\n",
       "      <td>0.496461</td>\n",
       "      <td>0.900159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.441748</td>\n",
       "      <td>0.426799</td>\n",
       "      <td>0.619448</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>0.899204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.477118</td>\n",
       "      <td>0.466179</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.529320</td>\n",
       "      <td>0.903620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.473090</td>\n",
       "      <td>0.468198</td>\n",
       "      <td>0.636255</td>\n",
       "      <td>0.539440</td>\n",
       "      <td>0.905569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.463141</td>\n",
       "      <td>0.459984</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.549758</td>\n",
       "      <td>0.901551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.469494</td>\n",
       "      <td>0.465534</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.521142</td>\n",
       "      <td>0.906722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.469616</td>\n",
       "      <td>0.495697</td>\n",
       "      <td>0.691477</td>\n",
       "      <td>0.577444</td>\n",
       "      <td>0.904375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.479558</td>\n",
       "      <td>0.491007</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.561440</td>\n",
       "      <td>0.905091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>0.483413</td>\n",
       "      <td>0.471744</td>\n",
       "      <td>0.691477</td>\n",
       "      <td>0.560857</td>\n",
       "      <td>0.904694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.499711</td>\n",
       "      <td>0.497758</td>\n",
       "      <td>0.666267</td>\n",
       "      <td>0.569815</td>\n",
       "      <td>0.905370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.510372</td>\n",
       "      <td>0.481385</td>\n",
       "      <td>0.667467</td>\n",
       "      <td>0.559356</td>\n",
       "      <td>0.899920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.501145</td>\n",
       "      <td>0.501382</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.567258</td>\n",
       "      <td>0.905211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.516584</td>\n",
       "      <td>0.496750</td>\n",
       "      <td>0.642257</td>\n",
       "      <td>0.560209</td>\n",
       "      <td>0.907001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.523439</td>\n",
       "      <td>0.515670</td>\n",
       "      <td>0.651861</td>\n",
       "      <td>0.575822</td>\n",
       "      <td>0.910660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.517817</td>\n",
       "      <td>0.505032</td>\n",
       "      <td>0.662665</td>\n",
       "      <td>0.573209</td>\n",
       "      <td>0.904694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.544881</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>0.674670</td>\n",
       "      <td>0.573177</td>\n",
       "      <td>0.902307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.535080</td>\n",
       "      <td>0.504837</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.582741</td>\n",
       "      <td>0.908194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.545210</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.576779</td>\n",
       "      <td>0.909586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.542538</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.567667</td>\n",
       "      <td>0.908950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.565277</td>\n",
       "      <td>0.494468</td>\n",
       "      <td>0.697479</td>\n",
       "      <td>0.578685</td>\n",
       "      <td>0.900716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.554572</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.910024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.571222</td>\n",
       "      <td>0.537109</td>\n",
       "      <td>0.660264</td>\n",
       "      <td>0.592353</td>\n",
       "      <td>0.910819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.564876</td>\n",
       "      <td>0.504664</td>\n",
       "      <td>0.649460</td>\n",
       "      <td>0.567979</td>\n",
       "      <td>0.906245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.570723</td>\n",
       "      <td>0.521461</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.592324</td>\n",
       "      <td>0.908115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.556374</td>\n",
       "      <td>0.530318</td>\n",
       "      <td>0.661465</td>\n",
       "      <td>0.588675</td>\n",
       "      <td>0.911416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.584013</td>\n",
       "      <td>0.516187</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.590231</td>\n",
       "      <td>0.908393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.586963</td>\n",
       "      <td>0.530631</td>\n",
       "      <td>0.675870</td>\n",
       "      <td>0.594509</td>\n",
       "      <td>0.908154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>0.588568</td>\n",
       "      <td>0.537583</td>\n",
       "      <td>0.678271</td>\n",
       "      <td>0.599788</td>\n",
       "      <td>0.911615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.599530</td>\n",
       "      <td>0.525392</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.593946</td>\n",
       "      <td>0.907717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.601896</td>\n",
       "      <td>0.526075</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.597092</td>\n",
       "      <td>0.908910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.596784</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>0.665066</td>\n",
       "      <td>0.596661</td>\n",
       "      <td>0.909189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.600036</td>\n",
       "      <td>0.534515</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>0.601575</td>\n",
       "      <td>0.910979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.603943</td>\n",
       "      <td>0.533777</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.595541</td>\n",
       "      <td>0.909547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.614012</td>\n",
       "      <td>0.530402</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.596215</td>\n",
       "      <td>0.910143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.617530</td>\n",
       "      <td>0.535885</td>\n",
       "      <td>0.672269</td>\n",
       "      <td>0.596379</td>\n",
       "      <td>0.908512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.620494</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.686675</td>\n",
       "      <td>0.605611</td>\n",
       "      <td>0.910143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.624301</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.601480</td>\n",
       "      <td>0.910342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.625407</td>\n",
       "      <td>0.547809</td>\n",
       "      <td>0.660264</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>0.911496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.627792</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.684274</td>\n",
       "      <td>0.600632</td>\n",
       "      <td>0.910461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.629377</td>\n",
       "      <td>0.548228</td>\n",
       "      <td>0.668667</td>\n",
       "      <td>0.602488</td>\n",
       "      <td>0.910859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.629352</td>\n",
       "      <td>0.534337</td>\n",
       "      <td>0.681873</td>\n",
       "      <td>0.599156</td>\n",
       "      <td>0.910302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.630355</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.597471</td>\n",
       "      <td>0.910581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.628978</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.604526</td>\n",
       "      <td>0.912092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.635723</td>\n",
       "      <td>0.535748</td>\n",
       "      <td>0.674670</td>\n",
       "      <td>0.597237</td>\n",
       "      <td>0.911337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.640015</td>\n",
       "      <td>0.552124</td>\n",
       "      <td>0.686675</td>\n",
       "      <td>0.612092</td>\n",
       "      <td>0.912212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.640519</td>\n",
       "      <td>0.540856</td>\n",
       "      <td>0.667467</td>\n",
       "      <td>0.597528</td>\n",
       "      <td>0.910621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.643238</td>\n",
       "      <td>0.530065</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>0.598746</td>\n",
       "      <td>0.908831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.641001</td>\n",
       "      <td>0.546490</td>\n",
       "      <td>0.691477</td>\n",
       "      <td>0.610493</td>\n",
       "      <td>0.911535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.634216</td>\n",
       "      <td>0.555126</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.614890</td>\n",
       "      <td>0.912729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.638824</td>\n",
       "      <td>0.539981</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.605485</td>\n",
       "      <td>0.911535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.646982</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.684274</td>\n",
       "      <td>0.605417</td>\n",
       "      <td>0.911138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.547297</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.912092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.653345</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>0.600629</td>\n",
       "      <td>0.911496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.651210</td>\n",
       "      <td>0.555126</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.614890</td>\n",
       "      <td>0.912172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.650549</td>\n",
       "      <td>0.540490</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.605805</td>\n",
       "      <td>0.912172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.656188</td>\n",
       "      <td>0.538679</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>0.910064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.655884</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.696279</td>\n",
       "      <td>0.606377</td>\n",
       "      <td>0.911177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.652477</td>\n",
       "      <td>0.545802</td>\n",
       "      <td>0.686675</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.912053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.656399</td>\n",
       "      <td>0.539336</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.602754</td>\n",
       "      <td>0.911217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.660384</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.607124</td>\n",
       "      <td>0.910263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.659540</td>\n",
       "      <td>0.552326</td>\n",
       "      <td>0.684274</td>\n",
       "      <td>0.611260</td>\n",
       "      <td>0.911297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.663240</td>\n",
       "      <td>0.551527</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.614567</td>\n",
       "      <td>0.911456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.661973</td>\n",
       "      <td>0.542939</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.604997</td>\n",
       "      <td>0.911893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.665775</td>\n",
       "      <td>0.537523</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>0.603476</td>\n",
       "      <td>0.910819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.669408</td>\n",
       "      <td>0.536449</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.603258</td>\n",
       "      <td>0.910024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.663746</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.677071</td>\n",
       "      <td>0.602242</td>\n",
       "      <td>0.911058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.669205</td>\n",
       "      <td>0.538100</td>\n",
       "      <td>0.686675</td>\n",
       "      <td>0.603376</td>\n",
       "      <td>0.909905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.671017</td>\n",
       "      <td>0.534515</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>0.601575</td>\n",
       "      <td>0.910064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.668009</td>\n",
       "      <td>0.547758</td>\n",
       "      <td>0.674670</td>\n",
       "      <td>0.604626</td>\n",
       "      <td>0.910581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.672334</td>\n",
       "      <td>0.544256</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.610026</td>\n",
       "      <td>0.910103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.670963</td>\n",
       "      <td>0.544244</td>\n",
       "      <td>0.686675</td>\n",
       "      <td>0.607219</td>\n",
       "      <td>0.910501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.671049</td>\n",
       "      <td>0.552657</td>\n",
       "      <td>0.686675</td>\n",
       "      <td>0.612420</td>\n",
       "      <td>0.911217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.674668</td>\n",
       "      <td>0.547348</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.611964</td>\n",
       "      <td>0.911098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.671389</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.691477</td>\n",
       "      <td>0.609846</td>\n",
       "      <td>0.911217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.669428</td>\n",
       "      <td>0.547801</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>0.609899</td>\n",
       "      <td>0.911456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.672870</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.608144</td>\n",
       "      <td>0.911217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.671981</td>\n",
       "      <td>0.538677</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.606506</td>\n",
       "      <td>0.911337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.670183</td>\n",
       "      <td>0.542484</td>\n",
       "      <td>0.697479</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.911416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.672736</td>\n",
       "      <td>0.539535</td>\n",
       "      <td>0.696279</td>\n",
       "      <td>0.607966</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.668010</td>\n",
       "      <td>0.540769</td>\n",
       "      <td>0.692677</td>\n",
       "      <td>0.607368</td>\n",
       "      <td>0.911496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.665566</td>\n",
       "      <td>0.541746</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.605193</td>\n",
       "      <td>0.912013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.666590</td>\n",
       "      <td>0.541942</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.607181</td>\n",
       "      <td>0.912053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.666955</td>\n",
       "      <td>0.538028</td>\n",
       "      <td>0.687875</td>\n",
       "      <td>0.603793</td>\n",
       "      <td>0.911854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.667692</td>\n",
       "      <td>0.541509</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.606445</td>\n",
       "      <td>0.911933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.668496</td>\n",
       "      <td>0.544592</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.608373</td>\n",
       "      <td>0.912132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.668815</td>\n",
       "      <td>0.542533</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.607086</td>\n",
       "      <td>0.911973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.669049</td>\n",
       "      <td>0.540490</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.605805</td>\n",
       "      <td>0.911774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=0.12635106283757422, metrics={'train_runtime': 687.6485, 'train_samples_per_second': 58.315, 'train_steps_per_second': 1.309, 'total_flos': 1.0493441091072e+16, 'train_loss': 0.12635106283757422, 'epoch': 100.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_wnut_model\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",  \n",
    "    load_best_model_at_end=False,  \n",
    "    push_to_hub=False,  \n",
    "    logging_dir=\"./logs\",  \n",
    "    logging_steps=10,  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d748ab-e839-4d20-a670-137b499c6c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6690486669540405,\n",
       " 'eval_precision': 0.5404896421845574,\n",
       " 'eval_recall': 0.6890756302521008,\n",
       " 'eval_f1': 0.6058047493403694,\n",
       " 'eval_accuracy': 0.9117740652346857,\n",
       " 'eval_runtime': 0.9711,\n",
       " 'eval_samples_per_second': 73.114,\n",
       " 'eval_steps_per_second': 2.06,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f8d0ba-ebc1-462d-a20c-5245116049a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 109018533\n",
      "Trainable Parameters: 109018533\n",
      "Non-trainable Parameters: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "non_trainable_params = total_params - trainable_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "print(f\"Non-trainable Parameters: {non_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618f4e6-7ada-4daa-93c5-27a3a04b7bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
