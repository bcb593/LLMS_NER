{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bac23c1",
   "metadata": {},
   "source": [
    "# BERT Model: Manual Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99910b",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed02bf1-be04-44e6-8e30-f455a534d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john\\AppData\\Local\\Temp/ipykernel_13828/504462793.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "C:\\Users\\john\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e4838",
   "metadata": {},
   "source": [
    "#### Data Loading and Preperation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffa2b59-db14-493d-89e1-c374f764cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'ner_tags', 'split_tokens'],\n",
      "        num_rows: 8646\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'ner_tags', 'split_tokens'],\n",
      "        num_rows: 1526\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from json file:\n",
    "data_file_path ='../data/biloc_tagged_sequences.json'\n",
    "datasets = load_dataset('json', data_files=data_file_path, field='data')\n",
    "\n",
    "# Paramters for dataset train-test-split function: \n",
    "# Sets train-test split and seed of data shuffle\n",
    "test_size=0.15\n",
    "random_seed=42\n",
    "\n",
    "# Split dataset into train and test sets:\n",
    "datasets = datasets['train'].train_test_split(test_size=test_size, seed=random_seed)\n",
    "print(\"Dataset Structure:\")\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11f92b",
   "metadata": {},
   "source": [
    "#### Tokenize Data for BERT Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72e652e-c04b-4ae3-a379-97a525f61cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in BERT tokenizer bert-base-cased:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33cb812-f289-4a6e-a367-111733cf99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deals with special tokens and ensures correct label alignment:\n",
    "# Helps with tokenization due to dataset format\n",
    "def tokenize_and_align_labels(tokenizer, examples):\n",
    "    \n",
    "    tokenized_inputs = tokenizer(examples[\"split_tokens\"], truncation=True, padding=\"max_length\", \n",
    "                                 is_split_into_words=True, return_tensors=\"pt\")\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = [-100 if word_id is None else label[word_id] for word_id in word_ids]\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Converts batch input to tensor\n",
    "def convert_to_tensors(batch):\n",
    "    batch_tensors = {key: tensor(value) for key, value in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000f834d-5028-4384-8eef-885a51a43709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Dataset\n",
    "tokenized_datasets = datasets.map(lambda examples: tokenize_and_align_labels(tokenizer, examples), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872b2cd",
   "metadata": {},
   "source": [
    "#### Tokenized Dataset Formatting for Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5cacb7-1291-4b40-9393-6c888d0d4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataset for use with Pytorch:\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'token_type_ids', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c95b90-bad1-473d-a880-e3da6115a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pytorch DataLoader Objects for Train and Test Sets:\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "test_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71998b17",
   "metadata": {},
   "source": [
    "#### Load in pre-trained BERT Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed62c1e-c7b8-410c-9af8-f50f9aa104bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters:\n",
    "model_name = \"bert-base-cased\"  \n",
    "num_labels = 165\n",
    "\n",
    "# Loads in default model from HuggingFace:\n",
    "bert_model = AutoModel.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea796ab1",
   "metadata": {},
   "source": [
    "#### Model, Fine-tuner, and Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2731059e-0ef5-4879-8774-4dfc84661f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherits from pytorch.nn.module to add custom fine-tuning to model:\n",
    "class CustomNERModel(nn.Module):\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "        super(CustomNERModel, self).__init__()\n",
    "        self.bert = bert_model  # The BERT model\n",
    "        self.classifier = nn.Linear(bert_model.config.hidden_size, num_labels)  # Classifier\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        logits = self.classifier(sequence_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b119deed-367d-4f2d-bc7c-fe533f1f0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of custom fine-tuned BERT model\n",
    "model = CustomNERModel(bert_model, num_labels)\n",
    "train_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9e9695-1d56-4a83-9bf2-4987eef53adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization of Optimizer and Loss Function:\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f8ce0",
   "metadata": {},
   "source": [
    "#### Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "635eb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint Function:\n",
    "def checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "def resume(model, filename):\n",
    "    model.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2160abce-c668-4e02-bc27-8fcb6fd21fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "if train_mode:\n",
    "    num_epochs = 50\n",
    "    save_path = './checkpoints/model'\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch in progress_bar:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs\n",
    "            loss = loss_function(logits.view(-1, num_labels), labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        # Generates Model Checkpoint Every 10 Epochs\n",
    "        if epoch != 0 and epoch % 10 == 0:\n",
    "            checkpoint(model, save_path + str(epoch // 10))\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "else:\n",
    "    model_path = './checkpoints/model'\n",
    "    resume(model, model_path + \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0be57e",
   "metadata": {},
   "source": [
    "#### Model Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd304d23-2cca-4211-8147-9465be2d1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_list = []\n",
    "pred_labels_list = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch in test_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        \n",
    "        true_labels_list.append(labels)\n",
    "        pred_labels_list.append(predictions)\n",
    "\n",
    "true_labels_flat = np.concatenate(true_labels_list, axis=None)\n",
    "pred_labels_flat = np.concatenate(pred_labels_list, axis=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ea2ab",
   "metadata": {},
   "source": [
    "#### Prediction Analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba1891d5-4ae0-4f04-8f6b-03b39e23be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9269\n",
      "Precision: 0.9236\n",
      "Recall: 0.9269\n",
      "F1 Score: 0.9234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\john\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "mask = true_labels_flat != -100 \n",
    "true_labels_filtered = true_labels_flat[mask]\n",
    "pred_labels_filtered = pred_labels_flat[mask]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels_filtered, pred_labels_filtered, average='weighted')\n",
    "accuracy = accuracy_score(true_labels_filtered, pred_labels_filtered)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9b363",
   "metadata": {},
   "source": [
    "#### Model Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2103bc4-b1c1-4fcc-8b1f-715af53bcff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 108437157\n",
      "Trainable Parameters: 108437157\n",
      "Non-trainable Parameters: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "non_trainable_params = total_params - trainable_params\n",
    "\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "print(f\"Non-trainable Parameters: {non_trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2cc25",
   "metadata": {},
   "source": [
    "#### Save True and Predicted Labels for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e6fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/true_labels.ob\", 'wb') as fp:\n",
    "    pickle.dump(true_labels_filtered, fp)\n",
    "    \n",
    "with open(\"../data/pre_labels.ob\", 'wb') as fp:\n",
    "    pickle.dump(pred_labels_filtered, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
