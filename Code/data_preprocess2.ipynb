{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938f51c6",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notebook 2\n",
    "\n",
    "This notebook aggregates a portion of the different scripts used to preprocess the CUAD dataset for use in NER token classification via LLM's.  \n",
    "\n",
    "### Script Section - Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7382ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import pybmoore\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3e22a",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Loads data saved from previous preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7a374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads json file containing reorganized document clauses:\n",
    "# See below cell for schema\n",
    "with open(\"./data/rft_clauses.json\", \"r\") as file:\n",
    "    rft_clauses = json.load(file)\n",
    "    \n",
    "# Loads list of abbreviated clause type names:     \n",
    "with open(\"./data/clause_tag_names.ob\", \"rb\") as fp:\n",
    "    ctn = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286462ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "JSON SCHEMA\n",
    "rft_clauses:\n",
    "    document_index:\n",
    "        doc_filename:\n",
    "        clauses:\n",
    "            clause_type1: clause_list\n",
    "            clause_type2: clause_list\n",
    "                .\n",
    "                .\n",
    "                .\n",
    "            clause_type41: clause_list\n",
    "        locations:\n",
    "            clause_type1: clause_Loc_dict\n",
    "            clause_type2: clause_Loc_dict\n",
    "                .\n",
    "                .\n",
    "                .\n",
    "            clause_type41: clause_Loc_dict\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865f2fc3",
   "metadata": {},
   "source": [
    "### Document Clause Position Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e236fd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting File Retrieval\n",
      "0,1,2,3,5,6,7,8,9,10,11,12,14,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,38,39,40,42,43,44,45,46,48,49,50,51,52,53,54,55,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,117,118,119,120,121,122,124,125,126,127,130,132,133,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,154,155,156,157,158,159,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,287,288,289,290,291,292,293,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,314,315,316,317,318,319,322,323,324,326,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,349,351,352,353,354,355,356,357,358,359,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,381,382,383,384,385,386,387,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,471,473,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,502,503,504,505,506,507,508,509,"
     ]
    }
   ],
   "source": [
    "N = len(rft_clauses)\n",
    "dataset_filepath = 'C:\\\\Users\\\\john\\\\LLM_NER_DATA\\\\CUAD_v1'\n",
    "text_doc_folder = 'full_contract_txt'\n",
    "text_doc_filepath = os.path.join(dataset_filepath, text_doc_folder)\n",
    "\n",
    "# Files that could not be found or read correctly with the error type\n",
    "# Contains tuple -> (filename, error_type)\n",
    "file_error_type = []\n",
    "\n",
    "print(\"Starting File Retrieval\")\n",
    "for i in range(N):\n",
    "    # File Retrieval Section:\n",
    "    index = str(i)\n",
    "    filename = rft_clauses[index][\"doc_filename\"]\n",
    "    \n",
    "    # Handles file not found & read file errors\n",
    "    try:\n",
    "        # Attempts to open file at specified location\n",
    "        with open(os.path.join(text_doc_filepath,filename), 'r') as file:\n",
    "                # Attempts to read file into string removing & replacing '\\n' with ' '\n",
    "                doc_text = file.read().replace('\\n', ' ')\n",
    "    except Exception as e:\n",
    "        file_error_type.append((filename,type(e)))\n",
    "        continue\n",
    "        \n",
    "    # Text File Clause Search Section:\n",
    "    # Document Clause Dictionary: Indexed via clause tag types:\n",
    "    doc_clauses = rft_clauses[index]['clauses']\n",
    "    \n",
    "    # Clause Location Dictionary Object Instaniation:\n",
    "    doc_clauses_loc = {}\n",
    "    for tag_type in ctn:\n",
    "        # List of clause samples from text\n",
    "        tag_type_samples = doc_clauses[tag_type]\n",
    "        \n",
    "        if len(tag_type_samples) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Utilize Boyer-Moore algorithm to find every instance of each clause sample\n",
    "        # Returns dictionary of start,end index tuples for each sample\n",
    "        results = pybmoore.search_m(tag_type_samples, doc_text, ProcessPoolExecutor)\n",
    "        \n",
    "        # Add location of clause samples in text document to dictionary\n",
    "        doc_clauses_loc[tag_type] = results\n",
    "    \n",
    "    # Add Clause Location Dictionary to Document Dictionary\n",
    "    rft_clauses[index]['locations'] = doc_clauses_loc\n",
    "    \n",
    "    print(index, end=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b0727",
   "metadata": {},
   "source": [
    "### Saving of Clause Positions to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1aa0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clause Tagging Prep Pt. 2 Completed!\n"
     ]
    }
   ],
   "source": [
    "# Serializing json\n",
    "json_object_final = json.dumps(rft_clauses, indent=4)\n",
    " \n",
    "# Write to 'rft_clauses.json'\n",
    "with open(\"./data/rft_clauses_final.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object_final)\n",
    "    \n",
    "print()\n",
    "print(\"Clause Tagging Prep Pt. 2 Completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
